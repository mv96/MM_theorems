{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab4f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'page_no', 'top_left', 'bot_right',\n",
      "       'grobid_text', 'pdf_alto_text', 'fonts', 'label', 'Normal',\n",
      "       'Superscipt', 'Subscript', 'italics', 'bold', 'is_Proportional',\n",
      "       'is_Serif', 'font_color_red', 'font_color_green', 'font_color_blue',\n",
      "       'is_bold_manual', 'is_italic_manual', 'is_serif_manual',\n",
      "       'is_math_manual', 'new_font_size', 'pdf_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# loading the preprcessed dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/mv96/Desktop/dataset_tkb/test.csv\")\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latter-score",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>page_no</th>\n",
       "      <th>top_left</th>\n",
       "      <th>bot_right</th>\n",
       "      <th>grobid_text</th>\n",
       "      <th>pdf_alto_text</th>\n",
       "      <th>fonts</th>\n",
       "      <th>label</th>\n",
       "      <th>Normal</th>\n",
       "      <th>...</th>\n",
       "      <th>is_Serif</th>\n",
       "      <th>font_color_red</th>\n",
       "      <th>font_color_green</th>\n",
       "      <th>font_color_blue</th>\n",
       "      <th>is_bold_manual</th>\n",
       "      <th>is_italic_manual</th>\n",
       "      <th>is_serif_manual</th>\n",
       "      <th>is_math_manual</th>\n",
       "      <th>new_font_size</th>\n",
       "      <th>pdf_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(200.03563410896913, 1224.9484944798717)</td>\n",
       "      <td>(675, 1866)</td>\n",
       "      <td>Fact 6 Let G be a graph and let f (v) ≥ n/g(n)...</td>\n",
       "      <td>['Fact[~end_of_font~] 6[~end_of_font~] Let[~en...</td>\n",
       "      <td>['font0  font0  font0  font6  font0  font0  fo...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627877</td>\n",
       "      <td>0.248082</td>\n",
       "      <td>0.627877</td>\n",
       "      <td>0.051151</td>\n",
       "      <td>0.249075</td>\n",
       "      <td>1812.02037/journal-factor.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(200.03563410896913, 711.6682345668228)</td>\n",
       "      <td>(675, 1866)</td>\n",
       "      <td>Fact 8 Let S be a subset of E(G).An f -factor ...</td>\n",
       "      <td>['Fact[~end_of_font~] 8[~end_of_font~] Let[~en...</td>\n",
       "      <td>['font0  font0  font0  font6  font0  font0  fo...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249075</td>\n",
       "      <td>1812.02037/journal-factor.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(200.03563410896913, 1565.7368010805071)</td>\n",
       "      <td>(675, 1866)</td>\n",
       "      <td>Let A be an alternating circuit and S be a sub...</td>\n",
       "      <td>['Fact[~end_of_font~] 11[~end_of_font~] Let[~e...</td>\n",
       "      <td>['font0  font0  font0  font6  font0  font0  fo...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.088816</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.044231</td>\n",
       "      <td>0.249075</td>\n",
       "      <td>1812.02037/journal-factor.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(200.03563410896913, 255.4592491550138)</td>\n",
       "      <td>(675, 1866)</td>\n",
       "      <td>Fact 12 Let H be an f -factor of G and let Q b...</td>\n",
       "      <td>['Fact[~end_of_font~] 12[~end_of_font~] Let[~e...</td>\n",
       "      <td>['font0  font0  font0  font6  font0  font0  fo...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.249075</td>\n",
       "      <td>1812.02037/journal-factor.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(200.03563410896913, 1610.1379192173042)</td>\n",
       "      <td>(675, 1866)</td>\n",
       "      <td>Observation 14 Let G be an undirected graph an...</td>\n",
       "      <td>['Observation[~end_of_font~] 14[~end_of_font~]...</td>\n",
       "      <td>['font0  font0  font0  font6  font0  font0  fo...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.249075</td>\n",
       "      <td>1812.02037/journal-factor.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388804</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(241.1818527361057, 480.18781204012924)</td>\n",
       "      <td>(840, 2132)</td>\n",
       "      <td>1. If w ∈ L then 2 3 ≤ g(w) f (w) ≤ 1, 2. If w...</td>\n",
       "      <td>['1.[~end_of_font~] If[~end_of_font~] w[~end_o...</td>\n",
       "      <td>['font1  font1  font11  font14  font11  font1 ...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>0.753401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187075</td>\n",
       "      <td>0.260075</td>\n",
       "      <td>1602.06073/main.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388805</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(200.03563410896913, 657.097648821723)</td>\n",
       "      <td>(840, 2132)</td>\n",
       "      <td>Here, FP is the class of functions from bit st...</td>\n",
       "      <td>['Here,[~end_of_font~] FP[~end_of_font~] is[~e...</td>\n",
       "      <td>['font1  font1  font1  font1  font1  font1  fo...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.284519</td>\n",
       "      <td>1602.06073/main.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388806</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(200.03563410896913, 795.191239021899)</td>\n",
       "      <td>(840, 2132)</td>\n",
       "      <td>Theorem 1.For any group oracle B = {B n }, the...</td>\n",
       "      <td>['Theorem[~end_of_font~] 1.[~end_of_font~] For...</td>\n",
       "      <td>['font16  font16  font2  font2  font2  font2  ...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>0.907005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.746377</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.105072</td>\n",
       "      <td>0.289610</td>\n",
       "      <td>1602.06073/main.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388807</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(200.03563410896913, 906.0551072107728)</td>\n",
       "      <td>(840, 2132)</td>\n",
       "      <td>H ≡ g 1 , ..., g k in time polynomial in n+log...</td>\n",
       "      <td>['H[~end_of_font~] ≡[~end_of_font~]g[~end_of_f...</td>\n",
       "      <td>['font11  font14 font11 font12 font11  font11 ...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.270025</td>\n",
       "      <td>1602.06073/main.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388808</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(200.03563410896913, 1690.465599150646)</td>\n",
       "      <td>(840, 2132)</td>\n",
       "      <td>2. For any uniform family of polynomial-size q...</td>\n",
       "      <td>['Theorem[~end_of_font~] 2.[~end_of_font~] For...</td>\n",
       "      <td>['font16  font16  font2  font2  font2  font2  ...</td>\n",
       "      <td>theorem</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.931723</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.297630</td>\n",
       "      <td>1602.06073/main.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385368 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  page_no  \\\n",
       "0               36            36      6.0   \n",
       "1               40            40      7.0   \n",
       "2               43            43      7.0   \n",
       "3               45            45      8.0   \n",
       "4               52            52      8.0   \n",
       "...            ...           ...      ...   \n",
       "388804          13            13      3.0   \n",
       "388805          14            14      3.0   \n",
       "388806          18            18      4.0   \n",
       "388807          19            19      4.0   \n",
       "388808          67            67      8.0   \n",
       "\n",
       "                                        top_left    bot_right  \\\n",
       "0       (200.03563410896913, 1224.9484944798717)  (675, 1866)   \n",
       "1        (200.03563410896913, 711.6682345668228)  (675, 1866)   \n",
       "2       (200.03563410896913, 1565.7368010805071)  (675, 1866)   \n",
       "3        (200.03563410896913, 255.4592491550138)  (675, 1866)   \n",
       "4       (200.03563410896913, 1610.1379192173042)  (675, 1866)   \n",
       "...                                          ...          ...   \n",
       "388804   (241.1818527361057, 480.18781204012924)  (840, 2132)   \n",
       "388805    (200.03563410896913, 657.097648821723)  (840, 2132)   \n",
       "388806    (200.03563410896913, 795.191239021899)  (840, 2132)   \n",
       "388807   (200.03563410896913, 906.0551072107728)  (840, 2132)   \n",
       "388808   (200.03563410896913, 1690.465599150646)  (840, 2132)   \n",
       "\n",
       "                                              grobid_text  \\\n",
       "0       Fact 6 Let G be a graph and let f (v) ≥ n/g(n)...   \n",
       "1       Fact 8 Let S be a subset of E(G).An f -factor ...   \n",
       "2       Let A be an alternating circuit and S be a sub...   \n",
       "3       Fact 12 Let H be an f -factor of G and let Q b...   \n",
       "4       Observation 14 Let G be an undirected graph an...   \n",
       "...                                                   ...   \n",
       "388804  1. If w ∈ L then 2 3 ≤ g(w) f (w) ≤ 1, 2. If w...   \n",
       "388805  Here, FP is the class of functions from bit st...   \n",
       "388806  Theorem 1.For any group oracle B = {B n }, the...   \n",
       "388807  H ≡ g 1 , ..., g k in time polynomial in n+log...   \n",
       "388808  2. For any uniform family of polynomial-size q...   \n",
       "\n",
       "                                            pdf_alto_text  \\\n",
       "0       ['Fact[~end_of_font~] 6[~end_of_font~] Let[~en...   \n",
       "1       ['Fact[~end_of_font~] 8[~end_of_font~] Let[~en...   \n",
       "2       ['Fact[~end_of_font~] 11[~end_of_font~] Let[~e...   \n",
       "3       ['Fact[~end_of_font~] 12[~end_of_font~] Let[~e...   \n",
       "4       ['Observation[~end_of_font~] 14[~end_of_font~]...   \n",
       "...                                                   ...   \n",
       "388804  ['1.[~end_of_font~] If[~end_of_font~] w[~end_o...   \n",
       "388805  ['Here,[~end_of_font~] FP[~end_of_font~] is[~e...   \n",
       "388806  ['Theorem[~end_of_font~] 1.[~end_of_font~] For...   \n",
       "388807  ['H[~end_of_font~] ≡[~end_of_font~]g[~end_of_f...   \n",
       "388808  ['Theorem[~end_of_font~] 2.[~end_of_font~] For...   \n",
       "\n",
       "                                                    fonts    label    Normal  \\\n",
       "0       ['font0  font0  font0  font6  font0  font0  fo...  theorem  1.000000   \n",
       "1       ['font0  font0  font0  font6  font0  font0  fo...  theorem  1.000000   \n",
       "2       ['font0  font0  font0  font6  font0  font0  fo...  theorem  1.000000   \n",
       "3       ['font0  font0  font0  font6  font0  font0  fo...  theorem  1.000000   \n",
       "4       ['font0  font0  font0  font6  font0  font0  fo...  theorem  1.000000   \n",
       "...                                                   ...      ...       ...   \n",
       "388804  ['font1  font1  font11  font14  font11  font1 ...  theorem  0.753401   \n",
       "388805  ['font1  font1  font1  font1  font1  font1  fo...  theorem  0.855903   \n",
       "388806  ['font16  font16  font2  font2  font2  font2  ...  theorem  0.907005   \n",
       "388807  ['font11  font14 font11 font12 font11  font11 ...  theorem  0.710417   \n",
       "388808  ['font16  font16  font2  font2  font2  font2  ...  theorem  0.987500   \n",
       "\n",
       "        ...  is_Serif  font_color_red  font_color_green  font_color_blue  \\\n",
       "0       ...       0.0             0.0               0.0              0.0   \n",
       "1       ...       0.0             0.0               0.0              0.0   \n",
       "2       ...       0.0             0.0               0.0              0.0   \n",
       "3       ...       0.0             0.0               0.0              0.0   \n",
       "4       ...       0.0             0.0               0.0              0.0   \n",
       "...     ...       ...             ...               ...              ...   \n",
       "388804  ...       0.0             0.0               0.0              0.0   \n",
       "388805  ...       0.0             0.0               0.0              0.0   \n",
       "388806  ...       0.0             0.0               0.0              0.0   \n",
       "388807  ...       0.0             0.0               0.0              0.0   \n",
       "388808  ...       0.0             0.0               0.0              0.0   \n",
       "\n",
       "        is_bold_manual  is_italic_manual  is_serif_manual  is_math_manual  \\\n",
       "0             0.627877          0.248082         0.627877        0.051151   \n",
       "1             0.857143          0.142857         0.857143        0.000000   \n",
       "2             0.866953          0.088816         0.866953        0.044231   \n",
       "3             0.772727          0.181818         0.772727        0.045455   \n",
       "4             0.578947          0.210526         0.578947        0.105263   \n",
       "...                ...               ...              ...             ...   \n",
       "388804        0.000000          0.278912         0.000000        0.187075   \n",
       "388805        0.000000          0.080109         0.000000        0.023438   \n",
       "388806        0.055556          0.746377         0.055556        0.105072   \n",
       "388807        0.000000          0.420833         0.000000        0.229167   \n",
       "388808        0.035714          0.931723         0.035714        0.017857   \n",
       "\n",
       "        new_font_size                       pdf_path  \n",
       "0            0.249075  1812.02037/journal-factor.pdf  \n",
       "1            0.249075  1812.02037/journal-factor.pdf  \n",
       "2            0.249075  1812.02037/journal-factor.pdf  \n",
       "3            0.249075  1812.02037/journal-factor.pdf  \n",
       "4            0.249075  1812.02037/journal-factor.pdf  \n",
       "...               ...                            ...  \n",
       "388804       0.260075            1602.06073/main.pdf  \n",
       "388805       0.284519            1602.06073/main.pdf  \n",
       "388806       0.289610            1602.06073/main.pdf  \n",
       "388807       0.270025            1602.06073/main.pdf  \n",
       "388808       0.297630            1602.06073/main.pdf  \n",
       "\n",
       "[385368 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e8bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = list(filter(lambda x: not x.startswith(\"Unnamed\"), list(df.columns)))\n",
    "font_vectors = df[cols_list].iloc[:, 7:-1]\n",
    "labels = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a5a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Superscipt</th>\n",
       "      <th>Subscript</th>\n",
       "      <th>italics</th>\n",
       "      <th>bold</th>\n",
       "      <th>is_Proportional</th>\n",
       "      <th>is_Serif</th>\n",
       "      <th>font_color_red</th>\n",
       "      <th>font_color_green</th>\n",
       "      <th>font_color_blue</th>\n",
       "      <th>is_bold_manual</th>\n",
       "      <th>is_italic_manual</th>\n",
       "      <th>is_serif_manual</th>\n",
       "      <th>is_math_manual</th>\n",
       "      <th>new_font_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.904917</td>\n",
       "      <td>0.027649</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.178749</td>\n",
       "      <td>0.213263</td>\n",
       "      <td>0.269013</td>\n",
       "      <td>0.070107</td>\n",
       "      <td>0.259792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.129550</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>0.070020</td>\n",
       "      <td>0.087247</td>\n",
       "      <td>0.027810</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.009674</td>\n",
       "      <td>0.331667</td>\n",
       "      <td>0.235511</td>\n",
       "      <td>0.383141</td>\n",
       "      <td>0.103025</td>\n",
       "      <td>0.021831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.862156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.946682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140423</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.264710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.077660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.316537</td>\n",
       "      <td>0.632343</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.272725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997099</td>\n",
       "      <td>0.780882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Normal     Superscipt      Subscript        italics  \\\n",
       "count  385368.000000  385368.000000  385368.000000  385368.000000   \n",
       "mean        0.904917       0.027649       0.049258       0.017161   \n",
       "std         0.129550       0.053174       0.070020       0.087247   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.862156       0.000000       0.000000       0.000000   \n",
       "50%         0.946682       0.000000       0.018223       0.000000   \n",
       "75%         1.000000       0.035088       0.077660       0.000000   \n",
       "max         1.000000       1.000000       0.854342       1.000000   \n",
       "\n",
       "                bold  is_Proportional       is_Serif  font_color_red  \\\n",
       "count  385368.000000    385368.000000  385368.000000   385368.000000   \n",
       "mean        0.002694         0.970731       0.000288        0.000460   \n",
       "std         0.027810         0.155894       0.014648        0.009713   \n",
       "min         0.000000         0.000000       0.000000        0.000000   \n",
       "25%         0.000000         1.000000       0.000000        0.000000   \n",
       "50%         0.000000         1.000000       0.000000        0.000000   \n",
       "75%         0.000000         1.000000       0.000000        0.000000   \n",
       "max         1.000000         1.000000       1.000000        0.997099   \n",
       "\n",
       "       font_color_green  font_color_blue  is_bold_manual  is_italic_manual  \\\n",
       "count     385368.000000    385368.000000   385368.000000     385368.000000   \n",
       "mean           0.000362         0.000444        0.178749          0.213263   \n",
       "std            0.007648         0.009674        0.331667          0.235511   \n",
       "min            0.000000         0.000000        0.000000          0.000000   \n",
       "25%            0.000000         0.000000        0.000000          0.014493   \n",
       "50%            0.000000         0.000000        0.000000          0.140423   \n",
       "75%            0.000000         0.000000        0.104167          0.316537   \n",
       "max            0.780882         1.000000        1.000000          1.000000   \n",
       "\n",
       "       is_serif_manual  is_math_manual  new_font_size  \n",
       "count    385368.000000   385368.000000  385368.000000  \n",
       "mean          0.269013        0.070107       0.259792  \n",
       "std           0.383141        0.103025       0.021831  \n",
       "min           0.000000        0.000000       0.000000  \n",
       "25%           0.000000        0.000000       0.247775  \n",
       "50%           0.009524        0.031229       0.264710  \n",
       "75%           0.632343        0.100000       0.272725  \n",
       "max           1.000000        1.000000       0.619675  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6feedca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Superscipt</th>\n",
       "      <th>Subscript</th>\n",
       "      <th>italics</th>\n",
       "      <th>bold</th>\n",
       "      <th>is_Proportional</th>\n",
       "      <th>is_Serif</th>\n",
       "      <th>font_color_red</th>\n",
       "      <th>font_color_green</th>\n",
       "      <th>font_color_blue</th>\n",
       "      <th>is_bold_manual</th>\n",
       "      <th>is_italic_manual</th>\n",
       "      <th>is_serif_manual</th>\n",
       "      <th>is_math_manual</th>\n",
       "      <th>new_font_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "      <td>385368.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.904917</td>\n",
       "      <td>0.027649</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.178749</td>\n",
       "      <td>0.213263</td>\n",
       "      <td>0.269013</td>\n",
       "      <td>0.070107</td>\n",
       "      <td>0.259792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.129550</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>0.070020</td>\n",
       "      <td>0.087247</td>\n",
       "      <td>0.027810</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.009674</td>\n",
       "      <td>0.331667</td>\n",
       "      <td>0.235511</td>\n",
       "      <td>0.383141</td>\n",
       "      <td>0.103025</td>\n",
       "      <td>0.021831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.862156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.946682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140423</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.264710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.077660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.316537</td>\n",
       "      <td>0.632343</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.272725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997099</td>\n",
       "      <td>0.780882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Normal     Superscipt      Subscript        italics  \\\n",
       "count  385368.000000  385368.000000  385368.000000  385368.000000   \n",
       "mean        0.904917       0.027649       0.049258       0.017161   \n",
       "std         0.129550       0.053174       0.070020       0.087247   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.862156       0.000000       0.000000       0.000000   \n",
       "50%         0.946682       0.000000       0.018223       0.000000   \n",
       "75%         1.000000       0.035088       0.077660       0.000000   \n",
       "max         1.000000       1.000000       0.854342       1.000000   \n",
       "\n",
       "                bold  is_Proportional       is_Serif  font_color_red  \\\n",
       "count  385368.000000    385368.000000  385368.000000   385368.000000   \n",
       "mean        0.002694         0.970731       0.000288        0.000460   \n",
       "std         0.027810         0.155894       0.014648        0.009713   \n",
       "min         0.000000         0.000000       0.000000        0.000000   \n",
       "25%         0.000000         1.000000       0.000000        0.000000   \n",
       "50%         0.000000         1.000000       0.000000        0.000000   \n",
       "75%         0.000000         1.000000       0.000000        0.000000   \n",
       "max         1.000000         1.000000       1.000000        0.997099   \n",
       "\n",
       "       font_color_green  font_color_blue  is_bold_manual  is_italic_manual  \\\n",
       "count     385368.000000    385368.000000   385368.000000     385368.000000   \n",
       "mean           0.000362         0.000444        0.178749          0.213263   \n",
       "std            0.007648         0.009674        0.331667          0.235511   \n",
       "min            0.000000         0.000000        0.000000          0.000000   \n",
       "25%            0.000000         0.000000        0.000000          0.014493   \n",
       "50%            0.000000         0.000000        0.000000          0.140423   \n",
       "75%            0.000000         0.000000        0.104167          0.316537   \n",
       "max            0.780882         1.000000        1.000000          1.000000   \n",
       "\n",
       "       is_serif_manual  is_math_manual  new_font_size  \n",
       "count    385368.000000   385368.000000  385368.000000  \n",
       "mean          0.269013        0.070107       0.259792  \n",
       "std           0.383141        0.103025       0.021831  \n",
       "min           0.000000        0.000000       0.000000  \n",
       "25%           0.000000        0.000000       0.247775  \n",
       "50%           0.009524        0.031229       0.264710  \n",
       "75%           0.632343        0.100000       0.272725  \n",
       "max           1.000000        1.000000       0.619675  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8529592a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385368, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.concat([font_vectors, labels], axis=1)\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3fe258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385368, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing nan values\n",
    "combined = combined.dropna()\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "793ff6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basic      194895\n",
       "proof      123010\n",
       "theorem     67463\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f6cdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAD4CAYAAAA+epuFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPV0lEQVR4nO3dfYxc5XXH8e+JDU4JYBxsoS2FLEQuKoGUFxNBCzRBDQ1xiprWkSBNYxJUK4GqoCptjJBoVbWSKWqLaBLAKKgvuJRCg7CKKpKmYClIAdYEbBPjYJArYjmkoGCiJEoKnP4xz9Lxsm+zu2dmvXw/0mjvPHNfzn3u3fube+fuTmQmkiRVeNugC5AkLVyGjCSpjCEjSSpjyEiSyhgykqQyiwddQLXly5fn8PDwoMuQpIPK1q1bX8zMFbOdz4IPmeHhYUZGRgZdhiQdVCLiv+diPl4ukySVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklRmwX9p2fa9+xlef/+gy5CkvtqzYfWgSwA8k5EkFTJkJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllykMmIoYjYscs53FxRKyfq5okSf1xUHyfTGZuBjYPug5JUm/6dblscURsioidEXFPRBwWEddFxGMRsSMiNkZEAETEH0bEtyNiW0T8S2u7LCK+0IaPiYh7I+LJ9viVPq2DJKlH/QqZk4AvZeYvAa8AVwBfyMyzMvMU4OeAj7Rx1wOnZ+Z7gc+MM6+bgC2Z+cvAGcBT5dVLkmakXyHzfGY+3IbvAM4FPhARj0TEduAC4D3t9W3Apoj4BPDqOPO6ALgZIDNfy8z9Y0eIiHURMRIRI6/9+E0vS5L6pF8hk+M8/xKwJjNPBW4D3t5eWw18kc5ZymMR0fPnRpm5MTNXZeaqRYctnUXZkqTZ6FfIHB8R57ThjwPfaMMvRsThwBqAiHgbcFxmPgh8HlgKHD5mXl8HPtvGXxQRpogkzVP9CpldwJURsRNYRudy123ADuAB4LE23iLgjnYJ7VvATZn58ph5XUXnUtt2YCtwcn35kqSZiMyxV7IWliVDK3No7Y2DLkOS+mrPhtWzmj4itmbmqtnW4V/8S5LKGDKSpDKGjCSpjCEjSSpjyEiSyhgykqQyhowkqYwhI0kqY8hIksoYMpKkMoaMJKmMISNJKmPISJLK9PyFYAebU49dysgs/xupJGlmPJORJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUpnFgy6g2va9+xlef/+gy5DmrT0bVg+6BC1gnslIksoYMpKkMoaMJKmMISNJKmPISJLKGDKSpDKGjCSpjCEjSSpjyEiSyhgykqQyhowkqYwhI0kqY8hIksoYMpKkMgdtyETExyJiZ0Q8OOhaJEnjmxchExGLZjDZ5cDvZ+YH5roeSdLcKA+ZiBiOiKcjYlM787gnIg6LiD0RcX1EPA58LCIujYjtEbEjIq7vmv5N7RFxHXAu8OWIuKF6HSRJM9Ovb8Y8Cbg8Mx+OiNuBK1r7S5l5RkT8PPBN4EzgB8BXI+K3gEeB68e2Z+afR8QFwOcyc2TswiJiHbAOYNGRK4pXTZI0kX5dLns+Mx9uw3fQOQsBuKv9PAt4KDP/JzNfBTYB50/SPqnM3JiZqzJz1aLDls7pikiSpq9fIZMTPP9Rn5YvSRqAfoXM8RFxThv+OPCNMa8/CvxaRCxvNwFcCmyZpF2SdBDoV8jsAq6MiJ3AMuDm7hczcx+wHngQeBLYmpn3TdTep5olSbPUrw/+X83MT4xpG+5+kpl3AneOnXCS9vfPYX2SpALz4u9kJEkLU/mZTGbuAU6pXo4kaf7xTEaSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJXp1z/IHJhTj13KyIbVgy5Dkt6SPJORJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUpnFgy6g2va9+xlef/+gy9AM7NmwetAlSJolz2QkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSmUlDJiKOiogr2vD7I+Lf+1OWJGkhmOpM5ijgisoCImLBf6eNJL1VTRUyG4B3R8QTwA3A4RFxT0Q8HRGbIiIAIuLMiNgSEVsj4oGIGGrtp0XENyNiW0TcGxHLWvtDEXFjRIwAV00y/UMR8bcRMRIROyPirIj4SkQ8ExF/UdUpkqS5MVXIrAeezczTgD8GTgeuBk4GTgR+NSIOAf4OWJOZZwK3A3/Zpv9H4POZ+V5gO/CnXfM+NDNXATdNMj3Az9p4twD3AVcCpwCXRcTRM1lpSVJ/9Hqp6tHM/C5AO7sZBl6mc9D/WjuxWQTsi4ilwFGZuaVN+w/A3V3zuqv9PGm86bvG29x+bgeeysx9bfnPAccBL40tMiLWAesAFh25osdVlCTNlV5D5qddw6+16YPOwf+c7hFbyEzmR6Ojjjf9OMt8fczyX2eC+jNzI7ARYMnQypyiDklSkakul/0QOGKKcXYBKyLiHICIOCQi3pOZ+4EfRMR5bbzfA7ZMd/ppr4Ekad6a9EwmM1+KiIcjYgfwE+CFccb5WUSsAW5qZy+LgRuBp4C1wC0RcRjwHPCpHqeXJB3EInNhX01aMrQyh9beOOgyNAN7NqwedAnSW1ZEbG03Xc2Kf/EvSSpjyEiSyhgykqQyhowkqYwhI0kqY8hIksoYMpKkMoaMJKmMISNJKmPISJLKGDKSpDKGjCSpjCEjSSrT65eWHXROPXYpI/43X0kaCM9kJEllDBlJUhlDRpJUxpCRJJUxZCRJZQwZSVIZQ0aSVMaQkSSVMWQkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUhlDRpJUxpCRJJUxZCRJZSIzB11DqYj4IbBr0HVMYTnw4qCLmII1zg1rnBvWOHtT1feuzFwx24Us+K9fBnZl5qpBFzGZiBixxtmzxrlhjXNjvtfYr/q8XCZJKmPISJLKvBVCZuOgC5gGa5wb1jg3rHFuzPca+1Lfgv/gX5I0OG+FMxlJ0oAYMpKkOpm5YB/Ah+j8jcxuYH3xso4DHgS+DTwFXNXa/wzYCzzRHh/umuaaVtsu4Demqhs4AXiktd8FHDqDOvcA21stI63tncDXgGfaz2WtPYCb2vK2AWd0zWdtG/8ZYG1X+5lt/rvbtNFjfSd19dUTwCvA1YPuR+B24PvAjq628n6baBk91HgD8HSr417gqNY+DPykqz9vmWktk63vNGss37bAkvZ8d3t9uMca7+qqbw/wxKD6kYmPNfNqf3xjXr0epA6WB7AIeBY4ETgUeBI4uXB5Q6MbDzgC+A5wcvsF+tw445/calrSfjGebTVPWDfwr8AlbfgW4LMzqHMPsHxM21/RflGB9cD1bfjDwH+0nfRs4JGuHe259nNZGx7doR9t40ab9qJZbsPvAe8adD8C5wNncOCBp7zfJlpGDzVeCCxuw9d31TjcPd6Y+fRUy0Tr20ON5dsWuIIWAMAlwF291Djm9b8GrhtUPzLxsWZe7Y9v1DvTA8B8fwDnAA90Pb8GuKaPy78P+OAkv0AH1AM80Goet+62sV/k/w8YB4zXQ117eHPI7AKGunbgXW34VuDSseMBlwK3drXf2tqGgKe72g8Ybwa1Xgg83IYH3o+MOaD0o98mWsZ0axzz2keBTZONN5NaJlrfHvqxfNuOTtuGF7fxJjzLnqR/AngeWDnofuwab/RYM+/2x8xc0J/JHEtnZxj13dZWLiKGgdPpnJYD/EFEbIuI2yNi2RT1TdR+NPByZr46pr1XCXw1IrZGxLrWdkxm7mvD3wOOmWGNx7bhse0zdQlwZ9fz+dSP0J9+m2gZM/FpOu9KR50QEd+KiC0RcV5X7b3WMhe/a9Xb9o1p2uv72/i9Og94ITOf6WobWD+OOdbMy/1xIYfMQETE4cC/AVdn5ivAzcC7gdOAfXROtQfp3Mw8A7gIuDIizu9+MTtvUXIglXWJiEOBi4G7W9N868cD9KPfZrOMiLgWeBXY1Jr2Acdn5unAHwH/HBFH9qOWcczrbTvGpRz4xmdg/TjOsWZO5jtd013GQg6ZvXQ+IBv1C62tTEQcQmejb8rMrwBk5guZ+Vpmvg7cBrxvivoman8JOCoiFo9p70lm7m0/v0/ng+D3AS9ExFBbhyE6H3rOpMa9bXhs+0xcBDyemS+0eudVPzb96LeJljFtEXEZ8BHgd9uBgcz8aWa+1Ia30vmM4xdnWMusftf6tG3fmKa9vrSNP21tut+mcxPAaO0D6cfxjjUzmG9f9seFHDKPASsj4oT2rvgSYHPVwiIigC8DOzPzb7rah7pG+yiwow1vBi6JiCURcQKwks6HbePW3Q4ODwJr2vRr6VyL7aXGd0TEEaPDdD7z2NFqWTvOfDcDn4yOs4H97VT5AeDCiFjWLm1cSOfa9z7glYg4u/XHJ3utscsB7xjnUz926Ue/TbSMaYmIDwF/AlycmT/ual8REYva8Il0+u25GdYy0fpOt8Z+bNvu2tcA/zUauD34dTqfVbxxKWkQ/TjRsWYG8+3P/jjVhzYH84POXRXfofPu4triZZ1L59RxG123YgL/ROdWwG1tAw11TXNtq20XXXdhTVQ3nbtpHqVzW+HdwJIeazyRzp04T9K59fHa1n408HU6tyX+J/DO1h7AF1sd24FVXfP6dKtjN/CprvZVdA4SzwJfoMdbmNs83kHnXebSrraB9iOdwNsH/C+da9SX96PfJlpGDzXupnPdfXSfHL3D6nfaPvAE8DjwmzOtZbL1nWaN5dsWeHt7vru9fmIvNbb2vwc+M2bcvvcjEx9r5tX+OPrw38pIksos5MtlkqQBM2QkSWUMGUlSGUNGklTGkJEklTFkJEllDBlJUpn/A+hYYeR//jQKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class imbalance in the data\n",
    "combined[\"label\"].value_counts().sort_values().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce424deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(385368, 15) (385368,)\n",
      "(346831, 15) (38537, 15) (346831,) (38537,)\n"
     ]
    }
   ],
   "source": [
    "X = combined.iloc[:, :-1]\n",
    "y = combined[\"label\"]\n",
    "\n",
    "# divide the dataset into test and train portions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a68fc7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basic      175405\n",
       "proof      110709\n",
       "theorem     60717\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still has imbalance\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e98c380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basic      19490\n",
       "proof      12301\n",
       "theorem     6746\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44c4da",
   "metadata": {},
   "source": [
    "# what type of train test split to use\n",
    "\n",
    "1. should you use the the pdf wise sampled data because many classifiers that work on distances will work better as \n",
    "    there would all the paragraphs of the pdf given above but one drawback many classifiers will get impacted by\n",
    "    class imbalance\n",
    "2. should you use splitting based on the amount of genereted sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114fe29",
   "metadata": {},
   "source": [
    "# Investigating sampling techniques\n",
    "\n",
    "## The question of which version to train the models on ? (undersampled, Oversampled, or something hybrid)\n",
    "\n",
    "* undersampling - The models trained are immune to class imbalances however we lose alot of data with this approach also faster to train since we have less data with us\n",
    "\n",
    "* oversampling - The models trained are also immune to class imbalances however are prone to overfitting and generally takes more time to train the classifiers\n",
    "\n",
    "* without any under/oversampling taken into account\n",
    "\n",
    "to investigate on which process yeilds better parameter we train 3 classifiers \n",
    "\n",
    "1. KNN - that involves distances measure (not impacted by class imbalances)\n",
    "2. Naive bayes - a probablistic model that gets impacted by class imbalances\n",
    "3. Logistic regression - when there is a huge class imbalance\n",
    "\n",
    "we calculate a weighted f1 score of all class over 10 fold cross validation then mean across the three classifiers built\n",
    "\n",
    "**evaluation is based upont the default parameters to reduce the runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "325719cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic      194895\n",
      "proof      123010\n",
      "theorem     67463\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# before under sampling shape\n",
    "y.value_counts()\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95cc4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "for i in range(len(y_train.value_counts()) - 1):\n",
    "    undersample = RandomUnderSampler(sampling_strategy=\"majority\", random_state=1)\n",
    "    try:\n",
    "        X_under, y_under = undersample.fit_resample(X_under, y_under)\n",
    "    except:\n",
    "        X_under, y_under = undersample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa666e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basic      60717\n",
       "proof      60717\n",
       "theorem    60717\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46a0f80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182151, 15) (182151,)\n",
      "(346831, 15) (346831,)\n"
     ]
    }
   ],
   "source": [
    "print(X_under.shape, y_under.shape)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af1810",
   "metadata": {},
   "source": [
    "# undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a86ddd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 33%|███████████████                              | 1/3 [00:03<00:06,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=4) 0.5489295255903758 0.5483042271064172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████               | 2/3 [00:03<00:01,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() 0.5331628523345446 0.5290240548044737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:07<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(n_jobs=4, random_state=0) 0.560723502064742 0.5627059708851234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for class imbalance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# my classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(n_jobs=4),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, n_jobs=4),\n",
    "]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# f1=f1_score(y_under, y_pred, average='weighted')\n",
    "# acc=accuracy_score(y_under, y_pred)\n",
    "\n",
    "scoring = [\"accuracy\", \"f1_weighted\", \"neg_log_loss\"]\n",
    "accs = []\n",
    "f1s = []\n",
    "\"\"\"\n",
    "for clf in tqdm(clfs):\n",
    "    scores=cross_validate(clf, X_under, y_under, scoring=scoring,n_jobs=4,cv=10)\n",
    "    mean_acc=np.mean(scores[\"test_accuracy\"])\n",
    "    mean_f1=np.mean(scores[\"test_f1_weighted\"])\n",
    "    mean_loss=np.mean(scores[\"test_neg_log_loss\"])\n",
    "    accs.append(mean_acc)\n",
    "    f1s.append(mean_f1)\n",
    "    \n",
    "print(accs,f1s)\n",
    "\"\"\"\n",
    "# evaluation on test data\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_scores_1 = []\n",
    "for clf in tqdm(clfs):\n",
    "    clf.fit(X_under, y_under)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    test_scores_1.append([clf, f1, acc])\n",
    "    print(clf, f1, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5fe2a",
   "metadata": {},
   "source": [
    "# without any under/oversampling has class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a9b7732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 33%|███████████████                              | 1/3 [00:06<00:13,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=4) 0.5677481547358162 0.5759140566209098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████               | 2/3 [00:07<00:03,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() 0.35257257728677976 0.5059034174948751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(n_jobs=4, random_state=0) 0.5481174305161812 0.5832057503178764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for class imbalance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# my classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(n_jobs=4),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, n_jobs=4),\n",
    "]\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1=f1_score(y_under, y_pred, average='weighted')\n",
    "# acc=accuracy_score(y_under, y_pred)\n",
    "\n",
    "scoring = [\"accuracy\", \"f1_weighted\"]\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "\"\"\"\n",
    "for clf in tqdm(clfs):\n",
    "    scores=cross_validate(clf, X_train, y_train, scoring=scoring,n_jobs=4,cv=10)\n",
    "    mean_acc=np.mean(scores[\"test_accuracy\"])\n",
    "    mean_f1=np.mean(scores[\"test_f1_weighted\"])\n",
    "    accs.append(mean_acc)\n",
    "    f1s.append(mean_f1)\n",
    "    \n",
    "print(accs,f1s)\n",
    "\"\"\"\n",
    "\n",
    "# evaluation on test data\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_scores_2 = []\n",
    "for clf in tqdm(clfs):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    test_scores_2.append([clf, f1, acc])\n",
    "    print(clf, f1, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bb2cd",
   "metadata": {},
   "source": [
    "# with oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f785fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 33%|███████████████                              | 1/3 [00:06<00:13,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=4) 0.5450861723957208 0.542465682331266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████               | 2/3 [00:08<00:03,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() 0.5324885050604752 0.5282455821677868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:18<00:00,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(n_jobs=4, random_state=0) 0.5620922718505574 0.5638217816643745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# for class imbalance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# my classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(n_jobs=4),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, n_jobs=4),\n",
    "]\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1=f1_score(y_under, y_pred, average='weighted')\n",
    "# acc=accuracy_score(y_under, y_pred)\n",
    "\n",
    "scoring = [\"accuracy\", \"f1_weighted\"]\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "\"\"\"\n",
    "for clf in tqdm(clfs):\n",
    "    scores=cross_validate(clf, X_over, y_over, scoring=scoring,n_jobs=4,cv=10)\n",
    "    mean_acc=np.mean(scores[\"test_accuracy\"])\n",
    "    mean_f1=np.mean(scores[\"test_f1_weighted\"])\n",
    "    accs.append(mean_acc)\n",
    "    f1s.append(mean_f1)\n",
    "    \n",
    "print(accs,f1s)\n",
    "\"\"\"\n",
    "\n",
    "# evaluation on test data\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_scores_3 = []\n",
    "for clf in tqdm(clfs):\n",
    "    clf.fit(X_over, y_over)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    test_scores_3.append([clf, f1, acc])\n",
    "    print(clf, f1, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecefb6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+----------------------------------------------+----------+---------+\n",
      "| Splitting Strategy | Data version |                  algorithm                   | test_acc | test_f1 |\n",
      "+--------------------+--------------+----------------------------------------------+----------+---------+\n",
      "|       Random       | random under |        KNeighborsClassifier(n_jobs=4)        |  0.5489  |  0.5483 |\n",
      "|       Random       | random under |               MultinomialNB()                |  0.5332  |  0.529  |\n",
      "|       Random       | random under | LogisticRegression(n_jobs=4, random_state=0) |  0.5607  |  0.5627 |\n",
      "|       Random       |    As is     |        KNeighborsClassifier(n_jobs=4)        |  0.5677  |  0.5759 |\n",
      "|       Random       |    As is     |               MultinomialNB()                |  0.3526  |  0.5059 |\n",
      "|       Random       |    As is     | LogisticRegression(n_jobs=4, random_state=0) |  0.5481  |  0.5832 |\n",
      "|       Random       | random over  |        KNeighborsClassifier(n_jobs=4)        |  0.5451  |  0.5425 |\n",
      "|       Random       | random over  |               MultinomialNB()                |  0.5325  |  0.5282 |\n",
      "|       Random       | random over  | LogisticRegression(n_jobs=4, random_state=0) |  0.5621  |  0.5638 |\n",
      "+--------------------+--------------+----------------------------------------------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# summarizing the techniques\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\n",
    "    \"Splitting Strategy\",\n",
    "    \"Data version\",\n",
    "    \"algorithm\",\n",
    "    \"test_acc\",\n",
    "    \"test_f1\",\n",
    "]\n",
    "splitting_strategy = \"Random\"\n",
    "test = [test_scores_1, test_scores_2, test_scores_3]\n",
    "for name, test_ in zip([\"random under\", \"As is\", \"random over\"], test):\n",
    "    for element in test_:\n",
    "        clf = element[0]\n",
    "        test_f1 = float(\"{0:.4f}\".format(element[1]))\n",
    "        test_acc = float(\"{0:.4f}\".format(element[2]))\n",
    "        x.add_row([splitting_strategy, name, clf, test_f1, test_acc])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318976c0",
   "metadata": {},
   "source": [
    "# another type of train test split technique (sample 90% of all pdf contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f558962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'page_no', 'top_left', 'bot_right',\n",
      "       'grobid_text', 'pdf_alto_text', 'fonts', 'label', 'Normal',\n",
      "       'Superscipt', 'Subscript', 'italics', 'bold', 'is_Proportional',\n",
      "       'is_Serif', 'font_color_red', 'font_color_green', 'font_color_blue',\n",
      "       'is_bold_manual', 'is_italic_manual', 'is_serif_manual',\n",
      "       'is_math_manual', 'new_font_size', 'pdf_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# divide the dataset into test and train portions\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/mv96/Desktop/dataset_tkb/test.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "cols_list = list(filter(lambda x: not x.startswith(\"Unnamed\"), list(df.columns)))\n",
    "\n",
    "font_vectors = df[cols_list].iloc[:, 7:-1]\n",
    "labels = df[[\"label\", \"pdf_path\"]]\n",
    "combined = pd.concat([font_vectors, labels], axis=1)\n",
    "df = combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6990b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610\n",
      "2349\n",
      "261\n",
      "(352106, 15) (352106,) (36413, 15) (36413,)\n"
     ]
    }
   ],
   "source": [
    "# rerunning this block will change the outputs several time\n",
    "from random import sample\n",
    "import math\n",
    "\n",
    "all_pdfs = list(df[\"pdf_path\"].unique())\n",
    "print(len(all_pdfs))\n",
    "train_pdfs = sample(\n",
    "    list(df[\"pdf_path\"].unique()),\n",
    "    math.floor(len(df[\"pdf_path\"].unique()) * 0.90),\n",
    ")\n",
    "print(len(train_pdfs))\n",
    "test_pdfs = [pdf for pdf in all_pdfs if pdf not in train_pdfs]\n",
    "print(len(test_pdfs))\n",
    "\n",
    "training_data = df[\n",
    "    df[\"pdf_path\"].isin(train_pdfs)\n",
    "]  # basically all the values that have training pdfs\n",
    "test_data = df[\n",
    "    df[\"pdf_path\"].isin(test_pdfs)\n",
    "]  # basically all the values that have training pdfs\n",
    "\n",
    "# filter out everything that startswith unnamed\n",
    "\n",
    "y_train = training_data[\"label\"]\n",
    "X_train = training_data.iloc[:, :-2]\n",
    "\n",
    "y_test = test_data[\"label\"]\n",
    "X_test = test_data.iloc[:, :-2]\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49702a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data[\"label\"].value_counts().sort_values().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1a0bf",
   "metadata": {},
   "source": [
    "# without under sample or over sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "730af159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 33%|███████████████                              | 1/3 [00:04<00:09,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=4) 0.5588011705841246 0.5683409771235548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████               | 2/3 [00:05<00:02,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() 0.34128796501932274 0.49847581907560484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:11<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(n_jobs=4, random_state=0) 0.5438562837196489 0.5811660670639607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for class imbalance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# my classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(n_jobs=4),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, n_jobs=4),\n",
    "]\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1=f1_score(y_under, y_pred, average='weighted')\n",
    "# acc=accuracy_score(y_under, y_pred)\n",
    "\n",
    "scoring = [\"accuracy\", \"f1_weighted\"]\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "\"\"\"\n",
    "for clf in tqdm(clfs):\n",
    "    scores=cross_validate(clf, X_train, y_train, scoring=scoring,n_jobs=4,cv=10)\n",
    "    mean_acc=np.mean(scores[\"test_accuracy\"])\n",
    "    mean_f1=np.mean(scores[\"test_f1_weighted\"])\n",
    "    accs.append(mean_acc)\n",
    "    f1s.append(mean_f1)\n",
    "\n",
    "print(accs,f1s)\n",
    "\"\"\"\n",
    "\n",
    "# evaluation on test data\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in tqdm(clfs):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(clf, f1, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb883bf",
   "metadata": {},
   "source": [
    "# undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ce9c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del X_under\n",
    "    del y_under\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "for i in range(len(y_train.value_counts()) - 1):\n",
    "    undersample = RandomUnderSampler(sampling_strategy=\"majority\", random_state=1)\n",
    "    try:\n",
    "        X_under, y_under = undersample.fit_resample(X_under, y_under)\n",
    "    except:\n",
    "        X_under, y_under = undersample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d11fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 33%|███████████████                              | 1/3 [00:03<00:06,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=4) 0.5578192780371037 0.5576579792931096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████               | 2/3 [00:03<00:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() 0.5385556982058242 0.5342872051190509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:07<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(n_jobs=4, random_state=0) 0.5665783996842056 0.5694669486172521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for class imbalance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# my classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(n_jobs=4),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, n_jobs=4),\n",
    "]\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1=f1_score(y_under, y_pred, average='weighted')\n",
    "# acc=accuracy_score(y_under, y_pred)\n",
    "\n",
    "scoring = [\"accuracy\", \"f1_weighted\"]\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "\"\"\"\n",
    "for clf in tqdm(clfs):\n",
    "    scores=cross_validate(clf, X_under, y_under, scoring=scoring,n_jobs=4,cv=10)\n",
    "    mean_acc=np.mean(scores[\"test_accuracy\"])\n",
    "    mean_f1=np.mean(scores[\"test_f1_weighted\"])\n",
    "    accs.append(mean_acc)\n",
    "    f1s.append(mean_f1)\n",
    "    \n",
    "print(accs,f1s)\n",
    "\"\"\"\n",
    "\n",
    "# evaluation on test data\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in tqdm(clfs):\n",
    "    clf.fit(X_under, y_under)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(clf, f1, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f950c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352106, 15) (352106,)\n",
      "(183867, 15) (183867,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_under.shape, y_under.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304727e",
   "metadata": {},
   "source": [
    "# oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a8220f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 33%|███████████████                              | 1/3 [00:05<00:11,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=4) 0.5439516379870877 0.5418943783813474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████               | 2/3 [00:07<00:03,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() 0.5391152738675088 0.5348364595062203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mv96/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:17<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(n_jobs=4, random_state=0) 0.567030013616919 0.5697141130914783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# for class imbalance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# my classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(n_jobs=4),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, n_jobs=4),\n",
    "]\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1=f1_score(y_under, y_pred, average='weighted')\n",
    "# acc=accuracy_score(y_under, y_pred)\n",
    "\n",
    "scoring = [\"accuracy\", \"f1_weighted\"]\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "\"\"\"\n",
    "for clf in tqdm(clfs):\n",
    "    scores=cross_validate(clf, X_over, y_over, scoring=scoring,n_jobs=4,cv=10)\n",
    "    mean_acc=np.mean(scores[\"test_accuracy\"])\n",
    "    mean_f1=np.mean(scores[\"test_f1_weighted\"])\n",
    "    accs.append(mean_acc)\n",
    "    f1s.append(mean_f1)\n",
    "    \n",
    "print(accs,f1s)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# evaluation on test data\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in tqdm(clfs):\n",
    "    clf.fit(X_over, y_over)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(clf, f1, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab7e88",
   "metadata": {},
   "source": [
    "# end of the the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e99bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f460e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0211d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_imb.shape, y_train_imb.shape, X_test_imb.shape, y_test_imb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dac2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the proportion of training and test data is balanced in both the cases\n",
    "print(y_train_imb.value_counts() / sum(y_train_imb.value_counts()))\n",
    "print(y_test_imb.value_counts() / sum(y_test_imb.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this runs in order of ND since fonts this might be able to capture the sequential as apect as most\n",
    "# likely the font neighbour nearest to it will be above or below the para\n",
    "# side advantage this also takes into account inter paper theorem blocks\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "neigh.fit(X_train_imb, y_train_imb)\n",
    "\n",
    "y_pred = neigh.predict(X_test_imb)\n",
    "acc = accuracy_score(y_test_imb, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will pick the absolute element from each list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d1ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
