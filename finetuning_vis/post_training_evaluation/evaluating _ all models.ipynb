{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efd8e2-db0a-4e33-a836-0557925785dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a91be-e37a-40ff-a02b-6c0decddefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"/gpfsscratch/rech/zpf/uyf36me/training_patches/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca2d14-7c30-4a81-987c-b12dba5884c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path=\"/gpfsscratch/rech/zpf/uyf36me/validation_patches/\"\n",
    "\n",
    "label_0=os.path.join(main_path,\"label_0/**.png\") #basic\n",
    "label_1=os.path.join(main_path,\"label_1/**.png\") #proof\n",
    "label_2=os.path.join(main_path,\"label_2/**.png\") #theorem\n",
    "label_3=os.path.join(main_path,\"label_3/**.png\") #overlap\n",
    "\n",
    "vals=[len(glob.glob(label_0)),len(glob.glob(label_1)),len(glob.glob(label_2)),len(glob.glob(label_3))]\n",
    "print(vals)\n",
    "print(\"ratios in the data --\")\n",
    "\n",
    "for val in vals:\n",
    "    print(val/sum(vals))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e1ff1-3559-41ab-9b6a-0b86d2b621fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def white_padding_and_scaling(default_shape,file_loc,overwrite=False):\n",
    "    \"\"\"\n",
    "    2- adds white padding wherever necessary\n",
    "    3- takes bitwise NOT transformation this esentially inverts the image sets black -0 as background while \n",
    "    255 is set as foreground\n",
    "    4- if overwrite true then makes a new file with '_t' suffix \n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_array=cv2.imread(file_loc)\n",
    "        shape=img_array.shape\n",
    "    except:\n",
    "        print(\"error in white padding--\",file_loc)\n",
    "        return\n",
    "\n",
    "    padding_height=0\n",
    "    padding_width=0\n",
    "    crop_width=False\n",
    "    crop_height=False\n",
    "\n",
    "    if(shape[0]<=default_shape[0]): #if img is small in width then we need padding then \n",
    "        padding_height=default_shape[0]-shape[0]\n",
    "    else:\n",
    "        crop_height=True\n",
    "        padding_height=0\n",
    "    if(shape[1]<=default_shape[1]):\n",
    "        padding_width=default_shape[1]-shape[1]\n",
    "    else:\n",
    "        crop_width=True\n",
    "        padding_width=0\n",
    "    if(padding_width>0 or padding_height>0):\n",
    "        colour_fill=(255,255,255) #colour to pad this is white\n",
    "        new_array=cv2.copyMakeBorder(img_array, 0,padding_height , 0, padding_width, cv2.BORDER_CONSTANT,value=colour_fill)\n",
    "    else:\n",
    "        new_array=img_array[0:default_shape[0], 0:default_shape[1]]\n",
    "\n",
    "    if(crop_width==True):\n",
    "        new_array=new_array[0:default_shape[0], 0:default_shape[1]]\n",
    "    if(crop_height==True):\n",
    "        new_array=new_array[0:default_shape[0], 0:default_shape[1]]\n",
    "\n",
    "\n",
    "    new_array=cv2.bitwise_not(new_array)\n",
    "    if(overwrite==True):\n",
    "        new_name=file_loc.replace(\".png\",\"_t.png\")\n",
    "        #print(new_name)\n",
    "        cv2.imwrite(new_name,new_array)\n",
    "        os.remove(file_loc)\n",
    "        return\n",
    "\n",
    "    return new_array\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce8c21-5d32-4478-9673-118251884385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset\n",
    "\n",
    "\n",
    "path=\"/gpfsscratch/rech/zpf/uyf36me/validation_patches/**/**.png\"\n",
    "\n",
    "png_files=glob.glob(path)\n",
    "\n",
    "\n",
    "            \n",
    "filtered_files=list(filter(lambda x: not x.endswith(\"_t.png\"),png_files))\n",
    "print(len(filtered_files))\n",
    "\n",
    "bad_files=list(filter(lambda x:  x.endswith(\"_t_t.png\"),png_files))\n",
    "print(len(bad_files))\n",
    "\n",
    "\n",
    "print(\"--running transformations\")\n",
    "image_shapes=(400,1400)\n",
    "n_jobs=-2\n",
    "#res=Parallel(n_jobs=n_jobs,backend=\"threading\",verbose=2)(delayed(white_padding_and_scaling)\n",
    "                                           #(default_shape=image_shapes,file_loc=fname,overwrite=True) for fname in tqdm(filtered_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b1b56-76ac-4589-b0a2-55de74eb568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy=tf.distribute.MirroredStrategy()\n",
    "devices=strategy.num_replicas_in_sync\n",
    "\n",
    "print(\"no of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf708720-9485-45a2-922b-b04ee8605c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes=(400,1400)\n",
    "batch_per_gpu=16\n",
    "batch_size=batch_per_gpu*devices\n",
    "\n",
    "sub_sample_validation_dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"/gpfsscratch/rech/zpf/uyf36me/validation_patches/\",\n",
    "    image_size=image_shapes,\n",
    "    batch_size=batch_size,\n",
    "    seed=2,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=False #<<<<<<<<change this when training\n",
    "    )\n",
    "\n",
    "sub_sample_validation_dataset=sub_sample_validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f217f641-e37f-4561-87d1-e4a8cf57707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4136/4136 [16:30<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "labels=None\n",
    "for x, y in tqdm(sub_sample_validation_dataset):\n",
    "    if(labels is None):\n",
    "        labels=y\n",
    "    else:\n",
    "        labels=np.concatenate([labels,y])\n",
    "        \n",
    "#ground truth        \n",
    "y_true=np.argmax(labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "348b8b1d-7e27-4187-bbb0-f1e61d429ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 529303 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "image_shapes=(400,1400)\n",
    "batch_per_gpu=16\n",
    "batch_size=batch_per_gpu*devices\n",
    "\n",
    "validation_dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"/gpfsscratch/rech/zpf/uyf36me/validation_patches/\",\n",
    "    image_size=image_shapes,\n",
    "    batch_size=batch_size,\n",
    "    seed=2,\n",
    "    shuffle=False #<<<<<<<<change this when training\n",
    "    )\n",
    "\n",
    "validation_dataset=validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebdca63-6122-4956-9736-a2e306a89b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/r_efficientnetv2m_avg5.h5\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 19:55:01.975996: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136/4136 [==============================] - 1480s 348ms/step - loss: 0.8327 - accuracy: 0.6402\n",
      "/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/r_efficientnetv2m_avg6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:20:08.397673: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136/4136 [==============================] - 1441s 341ms/step - loss: 0.8776 - accuracy: 0.6311\n",
      "/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/r_efficientnetv2m_avg7.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:44:35.707526: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136/4136 [==============================] - 1537s 364ms/step - loss: 0.7646 - accuracy: 0.6635\n",
      "/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/r_efficientnetv2m_avg8.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 21:10:38.998861: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136/4136 [==============================] - 1519s 360ms/step - loss: 0.7469 - accuracy: 0.6793\n",
      "/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/r_efficientnetv2m_avg9.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 21:36:23.785159: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136/4136 [==============================] - 1563s 370ms/step - loss: 0.7132 - accuracy: 0.6944\n",
      "/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/r_efficientnetv2s_avg1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 22:02:45.522005: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136/4136 [==============================] - 1116s 264ms/step - loss: 0.9448 - accuracy: 0.5938\n",
      "/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/r_efficientnetv2s_avg2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 22:21:39.215334: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 670/4136 [===>..........................] - ETA: 15:19 - loss: 0.7502 - accuracy: 0.7426"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.optimizers import AdamW ,LAMB\n",
    "txt_files=glob.glob(\"/gpfsdswork/projects/rech/zpf/uyf36me/finetuning_vision/new_models/**.txt\")\n",
    "txt_files.sort()\n",
    "txt_files\n",
    "\n",
    "epochs_run=[5,10,5,7,7,7,10,10]\n",
    "model_names=[]\n",
    "\n",
    "for file in txt_files:\n",
    "    model_name=file[:-4]\n",
    "    model_names.append(model_name)\n",
    "\n",
    "model_runs=[]\n",
    "for model in model_names:\n",
    "    for i in range(1,100):\n",
    "        model_path=model+str(i)+\".h5\"\n",
    "        if(os.path.exists(model_path)):\n",
    "            model_runs.append(model_path)\n",
    "            \n",
    "log_file=\"validation_runs.txt\"\n",
    "try:            \n",
    "    with open(log_file,\"r\") as fhand:\n",
    "        lines=fhand.readlines()\n",
    "\n",
    "    runs_so_far=[line.split(\",\")[0] for line in lines]\n",
    "    for element in runs_so_far:\n",
    "        if(element in model_runs):\n",
    "            model_runs.remove(element)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "def append_last_run(val,log_file):\n",
    "    with open(log_file,\"a\") as f:\n",
    "        f.write(val)\n",
    "\n",
    "\n",
    "for model_path in model_runs:\n",
    "    print(model_path)\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    val_loss,val_acc=model.evaluate(validation_dataset)\n",
    "    line_to_write=f'{model_path},{val_loss},{val_acc}\\n'\n",
    "    append_last_run(line_to_write,log_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa89b92-394a-4221-a086-e2ca87c9518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "055441bd-cf6d-4481-af13-901b155d6775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:00:31.196227: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 529303\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:9\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8271/8271 [==============================] - 2206s 265ms/step - loss: 0.8946 - accuracy: 0.6349\n",
      "0.8945791721343994 0.6349085569381714\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load model. Filepath is not an hdf5 file (or h5py is not available) or SavedModel. Received: filepath=<keras.engine.sequential.Sequential object at 0x14c04c62bee0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m val_loss,val_acc\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(validation_dataset)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_loss,val_acc)\n\u001b[0;32m---> 43\u001b[0m _f1_score\u001b[38;5;241m=\u001b[39m\u001b[43mevaluate_f1_for_tf_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_sample_validation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1 score of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_f1_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mevaluate_f1_for_tf_model\u001b[0;34m(model_path, validation_dataset, y_true, show_confusion_report)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Wrap the loaded model inside the strategy scope to distribute it across the GPUs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m---> 14\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#show model arch\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2022.05/envs/tensorflow-gpu-2.11.0+py3.10.8/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2022.05/envs/tensorflow-gpu-2.11.0+py3.10.8/lib/python3.10/site-packages/keras/saving/legacy/save.py:252\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile):\n\u001b[1;32m    248\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m hdf5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    249\u001b[0m                     filepath, custom_objects, \u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    250\u001b[0m                 )\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable) or SavedModel. Received: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m )\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load model. Filepath is not an hdf5 file (or h5py is not available) or SavedModel. Received: filepath=<keras.engine.sequential.Sequential object at 0x14c04c62bee0>"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from tensorflow_addons.optimizers import AdamW ,LAMB\n",
    "\n",
    "def evaluate_f1_for_tf_model(model_path,validation_dataset,y_true,show_confusion_report=True):\n",
    "    \n",
    "    #460h cpu for 28K images\n",
    "    # 4 A100 can do the job in\n",
    "\n",
    "    class_names=[\"Basic\",\"Proof\",\"Theorem\",\"Overlap\"]\n",
    "    \n",
    "\n",
    "    # Wrap the loaded model inside the strategy scope to distribute it across the GPUs\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "\n",
    "    #show model arch\n",
    "    print(model.summary())\n",
    "    \n",
    "\n",
    "    \n",
    "    #generating predictions\n",
    "    predictions=model.predict(validation_dataset)\n",
    "    \n",
    "    #generating predictions\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    if(show_confusion_report is True):\n",
    "        print('Confusion Matrix')\n",
    "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "        \n",
    "    return f1_score(y_true,y_pred,average=\"macro\")\n",
    "    \n",
    "#\"EfficientNetB0.h5\",\"EfficientNetB0_max.h5\",\"EfficientNetB0_avg.h5\",\n",
    "        #\"EfficientNetB4_avg.h5\",\"efficientnetv2s_avg.h5\",\n",
    "models=[\"./new_models/r_efficientnetv2s_avg11.h5\"]\n",
    "\n",
    "for model in models:\n",
    "    val_loss,val_acc=model.evaluate(validation_dataset)\n",
    "    print(val_loss,val_acc)\n",
    "    _f1_score=evaluate_f1_for_tf_model(model_path=model,validation_dataset=sub_sample_validation_dataset,y_true=y_true)\n",
    "    print(f\"f1 score of the {model} is {_f1_score}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e208781-67f6-4f2b-ac45-a9b15da25c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.optimizers import AdamW ,LAMB\n",
    "#460h cpu for 28K images\n",
    "# 4 A100 can do the job in\n",
    "\n",
    "class_names=[\"Basic\",\"Proof\",\"Theorem\",\"Overlap\"]\n",
    "model_path=\"efficientnetv2s_avg.h5\"\n",
    "\n",
    "# Wrap the loaded model inside the strategy scope to distribute it across the GPUs\n",
    "with strategy.scope():\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8ea4d-e0af-4660-9d96-3af2212676cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(sub_sample_validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7489f52c-3c12-46c9-bfd1-906dd8ddf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41568c5-3154-4823-b306-b3a5a65d4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7eee77-9739-44ee-8f10-c2d1e3c9e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.argmax(labels,axis=1)\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "050b3a95-bff7-41a1-bc86-810b8e0162dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[123291   1248  34516     16]\n",
      " [ 47168    987  16129      0]\n",
      " [  1812     35   5401     18]\n",
      " [   955      6    222      1]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.71      0.78      0.74    159071\n",
      "      Proofs       0.43      0.02      0.03     64284\n",
      "    Theorems       0.10      0.74      0.17      7266\n",
      "    Overlaps       0.03      0.00      0.00      1184\n",
      "\n",
      "    accuracy                           0.56    231805\n",
      "   macro avg       0.32      0.38      0.24    231805\n",
      "weighted avg       0.61      0.56      0.52    231805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Basic', 'Proofs', 'Theorems','Overlaps']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d7a0b-5f56-4ac4-a338-fcb8b4110de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model on larger dataset to see performance difference\n",
    "#use F1 score to measure the impact\n",
    "#decide the pooling part\n",
    "#do big arch lead to bad generalization\n",
    "#flops vs accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu-2.11.0_py3.10.8",
   "language": "python",
   "name": "module-conda-env-tensorflow-gpu-2.11.0_py3.10.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
